---
title: "RES Reproducibility Operations"
author: "<br> [Florian Oswald](https://floswald.github.io/)"
date: today
date-format: "D MMMM, YYYY"
subtitle: "Replicator Onboarding"
institute: "SciencesPo Paris"
format: 
  revealjs:
    theme: _extensions/metropolis-theme/metropolis.scss
    chalkboard: true
    logo: images/RES-logo.png
    footer: "RES Onboarding [Florian Oswald](https://floswald.github.io/)"
    incremental: false
    code-line-numbers: false
    highlight-style: github  
    slide-number: true
editor: visual
title-slide-attributes:
  data-background-image: /images/RES-logo1.png
  data-background-position: 85% 20%
  data-background-size: 25%
---

## Agenda

1. Overview of [Royal Economic Society](https://res.org.uk/) (RES) journal publication process
2. Overview of Reproducibility Operations
3. Workflow for RES Replicators
4. Handling an Example Package on `nuvolos.cloud`



# RES Journals

> üëâ The RES publishes two peer-reviewed journals: The Economic Journal (`EJ`) and The Econometrics Journal (`EctJ`)

::: footer
:::

------------------------------------------------------------------------

## RES Journals


::: {columns}
::: {.column width="45%"}

### The Economic Journal

::: fragment
- Traditional publication of RES. A *general interest* journal.
:::


::: fragment
-   First Published in March 1891.
:::

::: fragment
-   1 managing Editor (Francesco Lippi) and [8 Managing Editors](https://res.org.uk/journals/the-economic-journal/editorial-board/)
:::


::: fragment
-  [Google Scholar ranked](https://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bus_economics) 12th Econ Journal 
:::
:::

::: {.column width="45%"}

::: fragment
### The Econometrics Journal

- First published in 1998 by the RES, as a field journal in Econometrics.

- Managing Editor Jaap Abbring, 4 [managing editors](https://res.org.uk/journals/the-econometrics-journal/editors/)

:::
:::

:::

# Overview of Reproducibility Operations


> üëâ Our Operations are identical across both journals

::: footer
:::

-------------

## *Reproducibility* or *Replicability*?


::: {.callout-note}
# Replicability

relates to the reproduction of research findings using different methods, datasets, and assumptions. 
:::

. . .

::: {.callout-note}
# Reproducibility

relates to being able to reproduce the exact findings *in the original piece of research*, using the same data and code as the authors.
:::

. . .


::: {.callout-important}
# Necessary First Steps
At all major journals, we currently implement *Reproducibility Checks*. You may think it's a low bar, but *Reproducibility* is an necessary condition for *Replicability*.
:::


-----


## Who Cares?

* Well, all of us Economists and Social Scientists, and Researchers in general, *should* care. At stake is nothing less than the **credibility of our work**.

* All major journals are moving towards ensuring greater reproducibility. The role of the Data Editor and the valuable work of you replicators makes a big difference. (We have been submitting code and data for a long time, but... üôà)

* Initiatives like the [institute for Replication](https://i4replication.org/) aim to do replications in the above (i.e. more ambitious)  sense.

## What Do We Require

* The [group of social science Data Editors](https://social-science-data-editors.github.io/guidance/) has corrdinated on a fairly uniform policy for Economics papers.

* So, we require authors submit a replication package that *conforms to that policy*.

* `EJ` and `EctJ` policies are *almost* identical, I'm working on 100% overlap starting in October 2023.

* Our job: check compliance with the policy. 

* We Data Editors and Replicators are very different from the Managing Editors: there is little scope for discretion. Either your package complies with the policy, or it does not. Whether I *like* it or think it's *important* is irrelevant.


# Workflow for RES Replicators


> That's you guys! üí™üèΩ

::: footer
:::

-------------

## Workflow

* We have the full workflow [here](https://res-reproducibility.github.io/EJ-Workflow/)

* Doc gives full pipeline, so may be a bit lengthy.

* Let's zoom in on the parts more specific your involvement in more details.

-----


## Workflow: Basics

1. Pay: 25 Euros/hour
2. required: stable internet connection. If you have a stata/matlab/other  license on your machine, good, let me know. We have the cloud compute environment (more later).
3. Target turnaround: 1 week.
4. Feasibility checkpoint after: 60 minutes. (more later)


-----

## Glossary

Full [glossary here.](https://res-reproducibility.github.io/EJ-Workflow/)

| Abbreviation   | Meaning  | comments |
|-----    | -----  | ----- |
|`DE`| Data Editor | Manager of reproducibility checks
|`SS`| Shared Spreadsheet | log all operations, Replicator availability and time use.
|`DB`| Shared Dropbox folder | Dropbox folder storing all replication packages. *Read-only* access for everyone.



----

## Replicator Availability on **SS**

* The replicators declare their *current* availability to handle papers in the `SS`, tab `Replicator-Availability`

* by modifying column `Available to take on today (Replicators edit this column!)` 

* Setting this column to 2 would mean that the replicator can handle 2 packages *starting today*: 

![](images/step3.png)

----


## Replicator Timeline

1. The day a paper is assigned to a replicator, section of the `SS`  becomes <span style="background-color:green;">green</span>. 
2. Five days after, it automatically turns <span style="background-color:yellow;">yellow</span>
3. 10 days after assignment it turns <span style="background-color:red;">red</span>. 

. . .

::: {.callout-important}
# Target: 7 Days
Our target is for the replicator to **complete any given package within 7 days**. 
:::


----

## Workflow in Detail

**Dropbox Setup**:

```
.
‚îú‚îÄ‚îÄ EJ-1-key-documents
‚îú‚îÄ‚îÄ EJ-2-submitted-replication-packages  <----
‚îú‚îÄ‚îÄ EJ-3-replication-reports             <----
‚îú‚îÄ‚îÄ EJ-4-background-documents
‚îú‚îÄ‚îÄ EJ-5-back-office-data-editor
‚îú‚îÄ‚îÄ EJ-6-good-to-go
‚îî‚îÄ‚îÄ EJ-7-published-packages
```

1. Replicator navigates to shared `DB` folder `EJ-2-submitted-replication-packages`, and looks for the correct submission number and Author names.
1. Downloads a **copy** of the package to their local drive.


## Naming Conventions

::: {.callout-note}

# Naming Convention

Folders and Files *must* adhere to the naming convention `Lastname-XXXXXXXX`
where `XXXXXXXX` is the MS number of the paper.
:::

This means:

1. in `EJ-2-submitted-replication-packages`, look out for Author's last name and corresponding MS number.
2. In your report, use this exact naming convention, together with the revision number. That is, use
```
Lastname-XXXXXXXX-R2.doc
```
in revision 2.



----

## Workflow in Detail 2


1. Replicator starts clock. ‚è∞
1. Replicator studies the package, follows contained instructions, and tries to reproduce all results in the paper. If the contained instructions are insufficiently precise so that after 60 minutes the replicator has not gained an understanding of how they *will be able* to reproduce certain results, we abort and go to the next step. This does *not* include actual runtime, which can be significantly longer.
3. Replicator stops clock. ‚è∞ (Again, if program requires significant runtime, this is not billed as replicator time.)
3. Fills in reproducibility report, a template for which is stored in shared `DB` at `EJ-3-replication-reports`

----

## Workflow in Detail 3

4. Fills in corresponding section of `SS` with relevant data:
    * Completion date
    * Time spent (in hours. 1.9 hours is 1h 54min): *This information will determine the replicators payment.*
    * Whether the checks were successful or not (Y/N)
    * List the software used. Multiple softwares in comma separated list like `stata,fortran,matlab`. Do not include versions, like `stata 18 (MP2)`.
    * The type of Data Statement that should be published with the paper. This can be one of `A,S,T,P` or the combinations `A;T`, `A;S`, `A;S;T`. The meaning of each is explained in tab *Codes* of `SS`.
5. Replicator turns switch `Status` from *A* (assigned) to *B* (back to `DE`)


----

## Workflow detail 4: Checkout on **SS**


* Once more, this happens **after** the replicator wrote their report -  they fill out the section on `SS` to log 
![Replicator fills out spreadsheet after completion of checks.](images/rep-excel.png)

# Example Package on `Nuvolos`


-----

## Log on to Nuvolos


* [`https://nuvolos.cloud/`](https://nuvolos.cloud/)
* this is like your computer. But in the cloud and backed by MS Azure.
* You can use it to run intensive (long-running) jobs without blocking your own computer.



-----

## Final version of a Package

* Most packages will go through multiple rounds with us.
* The final version needs to be shared *by the authors* on [zenodo](https://zenodo.org/communities/ej-replication-repository?page=1&size=20)
* We want to have *full certainty* that what they publish is the final version of the package we signed off on. How could we achieve that?

. . .

* üëâ the `md5` hash.

![](images/md5.png){#fig-md5}


---


## The **md5** hash string

* After upload of authors, we will compute our version of the `md5` string on the accepted version of the replication package, located here in the shared `DB`:

```

‚îú‚îÄ‚îÄ EJ-2-submitted-replication-packages
    ‚îú‚îÄ‚îÄ Lastname-XXXXXXXX-R3
        ‚îú‚îÄ‚îÄ 3-replication-package.zip
```

* The computation of the `md5` on our side is straightfoward. On a Linux command line one would run

```bash
$ md5sum 3-replication-package.zip

93b6634a97954d6cbfefa56f9dff315e 
```

* The string `"93b6634a97954d6cbfefa56f9dff315e"` needs to match the string on zenodo, or the paper will not be released for publication.

# The End

Thanks for joining the Team!









